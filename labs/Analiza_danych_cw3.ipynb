{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza danych – ćwiczenia 3.\n",
    "### Pierwsza sieć neuronowa z Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autor: mgr inż. Bartosz Czech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wprowadzenie\n",
    "Zanim zaczniemy budować sieć neuronową opartą na dane dotyczące polimorfizmów pojedynczego nukleotydu, zapoznamy się z budową modelu sieci neuronowej przy pomocy biblioteki Keras. Jako, że temat ćwiczeń dotyczy zbudowania modelu klasyfikacyjnego, przykład zamieszczony w niniejszym ćwiczeniu również ilustruje implementację modelu dla problemu klasyfikacyjnego. Zbiór danych pochodzi z Breast Cancer Wisconsin (Diagnostic). Zawiera 569 wierszy (reprezentujących pacjentów) oraz 30 kolumn numerycznych (cech). Celem ćwiczenia jest zbudowanie klasyfikatora umożliwiającego diagnostykę pacjentów. Domyślnie załadowany zbiór danych to obiekt typu scikit-learn Bunch object, który swoją strukturą przypomina słownik, jednak metody z biblioteki **pandas** nie mogą być na tym obiekcie zastosowane. Chcemy sklasyfikować typ raka (złośliwy/łagodny) wykorzystując następujące kodowanie 1 – malignant (złośliwy) lub 0 – benign (łagodny)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = cancer.data # przypisanie tensoru\n",
    "y_data = cancer.target # przypisanie wektoru z informacją o typie raka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy zbiór traningowy oraz zbiór testowy. W tym modelu 30% losowych obserwacji zostało przypisanych do testowego zbioru testowego. 70% zostanie użytych do trenowania modelu. Zauważ, że argument stratify nie został uwzględniony – chcemy, aby dane były wylosowane bez uwzględnienia rozkładu zmiennej y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.35, random_state = 123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy pusty model typu Sequential. Typ Sequential charakteryzuje się liniowym stosem warstw i jest najpopularniejszą architekturą sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy dwie ukryte warstwy sieci, z 10 neuronami w każdej warstwie. W każdej warstwie używamy sigmoidalnej funkcji aktywacji. Więcej informacji o funkcjach aktywacji w keras znajduje się [tutaj.](https://keras.io/activations/). \n",
    "\n",
    "### Funkcja liniowa\n",
    "$f(x) = x$ \n",
    "* sygnał wejściowy = sygnał wejściowy\n",
    "* niemożliwa optymalizacja (propagacja wsteczna)\n",
    "* w pewnym sensie lepsza niż funkcja krokowa (wiele wyjść)\n",
    "* wszystkie warstwy sieci neuronowej są funkcją liniową; ostateczne wyjście jest kombinacją funkcji liniowych\n",
    "* ANN z funkcją identyczności = model regresji liniowej\n",
    "\n",
    "### Funkcja sigmoidalna (logistyczna)\n",
    "$f(x) = \\frac{1}{1 + e^{-x}}$ \n",
    "\n",
    "\n",
    "**zalety**\n",
    "* gładki gradient funkcji\n",
    "* przyjmuje wartości z zakresu 0-1 (normalizuje wyjście neuronu)\n",
    "* przejrzysta predykcja (dla |X|>2 y przyjmuje wartości bliskie krawędzi funkcji logistycznej)\n",
    "\n",
    "**wady**\n",
    "* w przypadku bardzo wysokich/niskich wartości X, predykcja nie ulega zmianie; gradient zanika\n",
    "* wyjścia nie są centrowane wokół 0\n",
    "* mało wydajna obliczeniowo\n",
    "\n",
    "### Funkcja Tanh (tangens hiperboliczny)\n",
    "$f(x) = tan(h) = \\frac{2}{1+e^{-2x}}-1$\n",
    "\n",
    "\n",
    "**zalety**\n",
    "* wyjścia centrowane są wokół 0 (ułatwia modelowanie danych, które są 'silnie' ujemne, 'silnie' dodatnie i neutralne\n",
    "\n",
    "**wady**\n",
    "* podobne jak w przypadku funkcji sigmoidalnej\n",
    "\n",
    "### Funkcja ReLU (Rectified Linear Unit)\n",
    "$f(x) \\begin{cases} % changed and corrected\n",
    "                    0 & jeśli \\; x<0 \\\\\n",
    "                    x &  jeśli \\;x \\geq 0.\n",
    "                \\end{cases}$\n",
    "\n",
    "\n",
    "**zalety**\n",
    "* wydajna obliczeniowo\n",
    "* nieliniowość (ma pochodną!)\n",
    "\n",
    "**wady**\n",
    "* jeśli dane na wejściu są zerowe, lub ujemne sieć nie może przeprowadzić propagacji wstecznej\n",
    "\n",
    "### Funkcja Leaky ReLU\n",
    "$f(x) = max(0,1x, x)$\n",
    "\n",
    "\n",
    "**zalety**\n",
    "* nie ma problemu z danymi zerowymi, lub ujemnymi; niewielkie nachylenie w obszarze ujemym\n",
    "\n",
    "**wady**\n",
    "* niska dokładność predykcji dla wejść ujemnych\n",
    "\n",
    "### Parametric ReLU\n",
    "$f(x) = max(\\alpha x, x)$\n",
    "\n",
    "\n",
    "**zalety**\n",
    "* nie przyjmuje stałej wartości 0.1, a jest dobierany odpowiedni współczynnik kierunkowy\n",
    "\n",
    "**wady**\n",
    "* dla każdego problemu może działać inaczej\n",
    "\n",
    "### Softmax\n",
    "$f(x) = \\frac{exp(x_{i})}{\\sum_{j}exp(x_{j}) }$\n",
    "\n",
    "\n",
    "**zalety**\n",
    "* możliwość klasyfikacji wielu klas\n",
    "* przydatny dla warstwy wyjściowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, input_shape = (30,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy optymalizator. Jego celem jest znalezienie minimum funkcji straty. Użyjemy tutaj optymalizatora SGD. Więcej optymizatorów dostępnych w keras można znaleźć [tutaj](https://keras.io/optimizers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompilujemy nasz model, podając funkcje optymalizującą, funkcję straty i miarę umożliwiającą kontrolowanie procesu uczenia. Definiujemy funkcję straty. Lista dostępnych funkcji straty znajduje się [tutaj](https://keras.io/losses/). Jedną z najbardziej znanych funkcji straty jest mean_squared_error, która używana jest również przy tworzeniu modelu regresji liniowej. Kolejnym argumentem jest metryka modelu. Zazwyczaj wybieramy dokładność (accuracy). Inne dostępne metryki znajdują się [tutaj](https://keras.io/metrics/). Inne, opcjonalne argumenty funkcji model.compile znajdują się  [tutaj](https://keras.io/models/model/#compile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczymy nasz model. Podajemy zbiór treningowy oraz jego etykiety. Definiujemy batch_size, epochs i verbose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.6881 - accuracy: 0.6396\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6779 - accuracy: 0.6396\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6723 - accuracy: 0.6396\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6685 - accuracy: 0.6396\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6663 - accuracy: 0.6396\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6634 - accuracy: 0.6396\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6615 - accuracy: 0.6396\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6604 - accuracy: 0.6396\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.6591 - accuracy: 0.6396\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.6584 - accuracy: 0.6396\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6578 - accuracy: 0.6396\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6569 - accuracy: 0.6396\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6562 - accuracy: 0.6396\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.6557 - accuracy: 0.6396\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.6555 - accuracy: 0.6396\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6552 - accuracy: 0.6396\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6552 - accuracy: 0.6396\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6550 - accuracy: 0.6396\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6550 - accuracy: 0.6396\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6550 - accuracy: 0.6396\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6549 - accuracy: 0.6396\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6548 - accuracy: 0.6396\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.6547 - accuracy: 0.6396\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.6544 - accuracy: 0.6396\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.6546 - accuracy: 0.6396\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6396\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.6543 - accuracy: 0.6396\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6396\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6396\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6396\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6396\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x143edb5f8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 30, epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 704us/step\n"
     ]
    }
   ],
   "source": [
    "results2 = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.673589153289795\n",
      "accuracy:  0.6050000190734863\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results2[0])\n",
    "print('accuracy: ', results2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss (strata)** – to wynik dobrania wag modelu. Czym mniejsza wartości funkcji straty, tym lepiej. Strata pokazuje, jak złe były prognozy modelu. Jeśli predykcja jest idealna, strata wynosi 0. W przeciwieństwie do dokładności, strata nie jest mierzona w procentach. Jest to suma błędów popełnionych dla każdego przykładu w zestawach uczących lub walidacyjnych.\\\n",
    "**Accuracy (dokładność)** – miara dokładności prognozy modelu w stosunku do prawdziwych danych. Załóżmy, że masz 1000 próbek testowych i jeśli Twój model jest w stanie poprawnie sklasyfikować 990 z nich, dokładność modelu wyniesie 99,0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miary oceny klasyfikatorów binarnych\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macierz błędu / tablica pomyłek (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  79]\n",
      " [  0 121]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        Macierz błędu\n",
    "\n",
    "|                     | Stan faktyczny 0 | Stan faktyczny 1 |\n",
    "|---------------------|----------------------|----------------------|\n",
    "| Stan klasyfikacji 0 | TP                   | FP                   |\n",
    "| Stan klasyfikacji 1 | FN                   | TN                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Typy błędów:***\n",
    "* TN - true negative, correct rejection - prawidłowa decyzja negatywna\n",
    "* TP - true positive, hit - prawidłowa decyzja pozytywna\n",
    "* FP - false positive, false alarm - błąd I rodzaju, wynik fałszywie pozytywny\n",
    "* FN - false negative, with miss - błąd II rodzaju, wynik fałszywie negatywny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Miary:***\n",
    "* ***Czułość*** (sensitivity, true positive rate, TPR, recall) - Interpretacja: Prawdopodobieństwo, że klasyfikacja będzie poprawna, pod warunkiem, że przypadek jest pozytywyny. Prawdopodobieństwo, że klasyfikacja dla błędnego genotypu wykaże, że jest on błędny.\n",
    "\n",
    "$TPR=\\frac{TP}{P}=\\frac{TP}{TP+FN}$\n",
    "\n",
    "* ***Specyficzność*** (specificity (SPC), true negative rate, TNR) - Interpretacja: Prawdopodobieństwo, że klasyfikacja będzie poprawna, pod warunkiem, że przypadek jest negatywny. Prawdopodobieństwo, że klasyfikacja dla poprawnego genotypu wykaże, że jest on poprawny.\n",
    "\n",
    "$SPC=\\frac{TN}{N}=\\frac{TN}{FP+TN}=1-FPR$\n",
    "\n",
    "* ***Częstość fałszywych alaramów*** (false positive rate, FPR, fall-out) - Interpretacja: Jak duża frakcja genotypów poprawnych zostanie zakwalifikowana jako błędny?\n",
    "\n",
    "$FPR=\\frac{FP}{N}=\\frac{FP}{FP+TN}=1-SPC$\n",
    "\n",
    "* ***Częstość fałszywych odkryć*** (false discovery rate, FDR, fall-out) - Interpretacja: Jak duża frakcja spośród genotypów zakwalifikowanych jako błędne jest fałszywa?\n",
    "\n",
    "$FDR=\\frac{FP}{FP+TP}$\n",
    "\n",
    "* ***Precyzja pozytywna*** (positive predictive value(PPV), precision) - Interpretacja: Jeśli genotyp został zaklasyfikowany jako błędny, jakie jest prawdopodobieństwwo, że genotyp jest rzeczywiście błędny?\n",
    "\n",
    "$PPV=\\frac{TP}{TP+FP}$\n",
    "\n",
    "* ***Precyzja negatywna*** (negative predictive value(NPV)) - Interpretacja: Jeśli genotyp został zaklasyfikowany jako poprawny, jakie jest prawdopodobieństwwo, że genotyp jest rzeczywiście poprawny?\n",
    "\n",
    "$PPV=\\frac{TN}{TN+FN}$\n",
    "\n",
    "* ***Dokładność*** (accuracy(ACC)) – Intepretacja: Prawdopodobieństwo prawidłowej klasyfikacji.\n",
    "\n",
    "$ACC=\\frac{TP+TN}{P+N}$\n",
    "\n",
    "* ***F1-score*** – średnia harmoniczna z precyzji i czułości – ocena balansu między precyzją a czułością. Miara nie uwzględnia wyników prawdziwie negatywnych.\n",
    "\n",
    "$F1=2\\frac{PPV*TPR}{PPV+TPR}=\\frac{2TP}{2TP+FP+FN}$\n",
    "\n",
    "* ***$F_{\\beta}$*** – uogólnienie powyższej miary. Parametr $\\beta$ oznacza wagę jaką przykładamy do PPV.\\\n",
    "$F_{\\beta}=(1+\\beta^{2})\\frac{PPV*TPR}{PPV\\beta^{2}+TPR}$\n",
    "\n",
    "* ***współczynnik korelacji Matthews (Matthews correlation coefficient)*** – zrównoważona miara oceny klasyfikatora. Uwzględnia wyniki prawdziwie i fałszywie pozytywne i negatywne. Może być stosowany, gdy klasy są różnej liczebności (niezbalansowane, unbalanced). MCC to współczynnik korelacji pomiędzy obserwowanymi i przewidywanymi klasyfikacjami binarnymi; przyjmuje wartości od -1 do 1, gdzie 1 to idealna klasyfikacja, 0 nie lepsza niż losowe przypisanie klasy, a -1 oznacza całkowitą rozbieżność pomiędzy klasyfikacją i stanem faktycznym.\n",
    "\n",
    "$MCC=\\frac{TP*TN-FP*FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie dodatkowe:\n",
    "* Dowiedz się czym jest krzywa ROC oraz na jej podstawie wyznacz miarę AUC. \n",
    "* Dowiedz się czym jest kroswalidacja (sprawdzian krzyżowy, cross-validation) i spróbuj zastosować tę metodę do budowy klasyfikatora. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
